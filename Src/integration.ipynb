{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory: d:\\KRISPI\\Code\\poisoning_detection\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Working Directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\KRISPI\\Code\\poisoning_detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\KRISPI\\Code\\poisoning_detection\\env\\lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Secure RAG System...\n",
      "Building RAG Knowledge Base...\n",
      "Generating embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a1ec1d00b664afaad4af757d7ff0a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2738 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge base built with 87585 items\n",
      "Knowledge base saved to knowledge_base.pkl\n",
      "Training poison detector...\n",
      "Computed centroids for 1798 genres\n",
      "Poison detector trained!\n",
      "Secure RAG System initialized successfully!\n",
      "\n",
      "==================================================\n",
      "SECURE RECOMMENDATIONS DEMO\n",
      "==================================================\n",
      "Filtered out 8 potentially poisoned items\n",
      "Query: 'action movies with comedy elements'\n",
      "\n",
      "Recommended Movies:\n",
      "Action Point (2018) | Comedy | Score: 0.989\n",
      "The New King of Comedy (2019) | Comedy | Score: 0.903\n",
      "The Humorist (2019) | Drama | Score: 0.821\n",
      "Actors (2000) | Comedy | Score: 0.820\n",
      "The Comedian (2016) | Comedy | Score: 0.819\n",
      "\n",
      "==================================================\n",
      "ATTACK-DEFENSE SIMULATION\n",
      "==================================================\n",
      "Starting Attack-Defense Simulation...\n",
      "Simulating poisoning attacks...\n",
      "Building RAG Knowledge Base...\n",
      "Generating embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb0cb2e41f846b98f9ee561f78664a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3011 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge base built with 96343 items\n",
      "Knowledge base saved to knowledge_base.pkl\n",
      "Filtered out 7 potentially poisoned items\n",
      "Filtered out 5 potentially poisoned items\n",
      "\n",
      "Simulation Results:\n",
      "           query  secure_recommendations  insecure_recommendations  \\\n",
      "0  action movies                       5                         5   \n",
      "1   comedy films                       5                         5   \n",
      "\n",
      "   poisoned_blocked  \n",
      "0                 0  \n",
      "1                 0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from engine import RAGRecommender\n",
    "from engine import CharacteristicVectorExtractor\n",
    "from engine import PoisonSimulator\n",
    "from engine import SimplePoisonDetector\n",
    "\n",
    "class SecureRAGSystem:\n",
    "    \"\"\"\n",
    "    Integrated System: RAG + Poison Detection\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.rag = RAGRecommender()\n",
    "        self.detector = None\n",
    "        self.poison_simulator = PoisonSimulator()\n",
    "        self.feature_extractor = CharacteristicVectorExtractor()\n",
    "        self.poisoned_items = set()\n",
    "        \n",
    "    def initialize_system(self, movies_df, build_detector=True):\n",
    "        \"\"\"\n",
    "        Initialize the complete system\n",
    "        \"\"\"\n",
    "        print(\"Initializing Secure RAG System...\")\n",
    "        \n",
    "        # Step 1: Build RAG knowledge base\n",
    "        self.rag.build_knowledge_base(movies_df)\n",
    "        \n",
    "        if build_detector:\n",
    "            # Step 2: Train poison detector on clean data\n",
    "            self._train_detector(movies_df)\n",
    "        \n",
    "        print(\"Secure RAG System initialized successfully!\")\n",
    "    \n",
    "    def _train_detector(self, clean_movies_df):\n",
    "        \"\"\"\n",
    "        Train poison detector using existing components\n",
    "        \"\"\"\n",
    "        print(\"Training poison detector...\")\n",
    "        \n",
    "        # Use existing feature extractor\n",
    "        descriptions = clean_movies_df['title'] + \" \" + clean_movies_df['genres'].astype(str)\n",
    "        genres = clean_movies_df['genres'].tolist()\n",
    "        \n",
    "        # Extract characteristics\n",
    "        characteristics = self.feature_extractor.batch_extract(descriptions.tolist())\n",
    "        \n",
    "        # Initialize and train detector\n",
    "        self.detector = SimplePoisonDetector(threshold=0.25)\n",
    "        self.detector.compute_centroids(characteristics, genres)\n",
    "        \n",
    "        print(\"Poison detector trained!\")\n",
    "    \n",
    "    def secure_recommend(self, query, top_k=10, filter_poisons=True):\n",
    "        \"\"\"\n",
    "        Get secure recommendations with poison filtering\n",
    "        \"\"\"\n",
    "        if not self.rag.is_built:\n",
    "            raise ValueError(\"RAG system not initialized. Call initialize_system() first.\")\n",
    "        \n",
    "        # Step 1: Get initial recommendations\n",
    "        candidates = self.rag.retrieve(query, top_k=top_k * 3)  # Get more for filtering\n",
    "        \n",
    "        if filter_poisons and self.detector:\n",
    "            # Step 2: Filter out detected poisons\n",
    "            candidates = self._filter_poisons(candidates)\n",
    "        \n",
    "        # Step 3: Rerank and return top_k\n",
    "        final_recommendations = self.rag._simulate_llm_reranking(candidates, query, top_k)\n",
    "        \n",
    "        # Add security info\n",
    "        final_recommendations['is_secure'] = True\n",
    "        \n",
    "        return final_recommendations.head(top_k)\n",
    "    \n",
    "    def _filter_poisons(self, candidates):\n",
    "        \"\"\"\n",
    "        Filter out poisoned items from candidates\n",
    "        \"\"\"\n",
    "        if self.detector is None:\n",
    "            return candidates\n",
    "        \n",
    "        # Extract characteristics for candidate items\n",
    "        candidate_descriptions = candidates['description'].tolist()\n",
    "        candidate_genres = candidates['genres'].tolist()\n",
    "        \n",
    "        characteristics = self.feature_extractor.batch_extract(candidate_descriptions)\n",
    "        \n",
    "        # Detect poisons\n",
    "        predictions, distances = self.detector.detect_poison(characteristics, candidate_genres)\n",
    "        \n",
    "        # Filter out poisoned items - FIXED VERSION\n",
    "        clean_indices = []\n",
    "        poisoned_indices = []\n",
    "        \n",
    "        for idx, pred in enumerate(predictions):\n",
    "            if not pred:  # If not poisoned\n",
    "                clean_indices.append(idx)\n",
    "            else:  # If poisoned\n",
    "                poisoned_indices.append(candidates.index[idx])\n",
    "        \n",
    "        # Get clean candidates using indices\n",
    "        clean_candidates = candidates.iloc[clean_indices].copy()\n",
    "        \n",
    "        # Store poisoned items for analysis\n",
    "        self.poisoned_items.update(poisoned_indices)\n",
    "        \n",
    "        print(f\"Filtered out {len(poisoned_indices)} potentially poisoned items\")\n",
    "        \n",
    "        return clean_candidates\n",
    "    \n",
    "    def simulate_attack_and_defense(self, movies_df, poison_ratio=0.1, test_queries=None):\n",
    "        \"\"\"\n",
    "        Complete simulation: Attack -> Defense -> Evaluation\n",
    "        \"\"\"\n",
    "        if test_queries is None:\n",
    "            test_queries = [\n",
    "                \"action comedy movies\",\n",
    "                \"emotional drama\", \n",
    "                \"scary horror films\",\n",
    "                \"romantic stories\"\n",
    "            ]\n",
    "        \n",
    "        print(\"Starting Attack-Defense Simulation...\")\n",
    "        \n",
    "        # Step 1: Generate poisoned dataset\n",
    "        print(\"Simulating poisoning attacks...\")\n",
    "        clean_df, poisoned_df = self.poison_simulator.generate_poisoned_dataset(\n",
    "            movies_df, poison_ratio=poison_ratio\n",
    "        )\n",
    "        \n",
    "        # Combine datasets (simulating real-world scenario)\n",
    "        test_df = pd.concat([clean_df, poisoned_df[poisoned_df['is_poisoned'] == True]])\n",
    "        \n",
    "        # Step 2: Rebuild RAG system with poisoned data\n",
    "        self.rag.build_knowledge_base(test_df)\n",
    "        \n",
    "        # Step 3: Test secure recommendations\n",
    "        results = []\n",
    "        for query in test_queries:\n",
    "            secure_recs = self.secure_recommend(query, top_k=5, filter_poisons=True)\n",
    "            insecure_recs = self.rag.recommend(query, top_k=5)  # Without filtering\n",
    "            \n",
    "            results.append({\n",
    "                'query': query,\n",
    "                'secure_recommendations': len(secure_recs),\n",
    "                'insecure_recommendations': len(insecure_recs),\n",
    "                'poisoned_blocked': len(insecure_recs) - len(secure_recs)\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "# Demo and testing\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data\n",
    "    movies = pd.read_csv('data/ml-32m/movies.csv')\n",
    "    \n",
    "    # Initialize secure system\n",
    "    secure_system = SecureRAGSystem()\n",
    "    secure_system.initialize_system(movies)\n",
    "    \n",
    "    # Test secure recommendations\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"SECURE RECOMMENDATIONS DEMO\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    test_query = \"action movies with comedy elements\"\n",
    "    recommendations = secure_system.secure_recommend(test_query, top_k=5)\n",
    "    \n",
    "    print(f\"Query: '{test_query}'\")\n",
    "    print(\"\\nRecommended Movies:\")\n",
    "    for idx, movie in recommendations.iterrows():\n",
    "        print(f\"{movie['title']} | {movie['genres']} | Score: {movie['similarity_score']:.3f}\")\n",
    "    \n",
    "    # Run attack-defense simulation\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ATTACK-DEFENSE SIMULATION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    simulation_results = secure_system.simulate_attack_and_defense(\n",
    "        movies, poison_ratio=0.1, test_queries=[\"action movies\", \"comedy films\"]\n",
    "    )\n",
    "    \n",
    "    print(\"\\nSimulation Results:\")\n",
    "    print(simulation_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
