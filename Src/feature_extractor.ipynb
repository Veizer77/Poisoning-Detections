{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7971dd5e882e48e6b8edd6f351c9ba23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "259f55df2d144e46ac624a049c5a05ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54cf7c5077cb4e7b952f0da9b8fa238a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b0599add5b2444380cefbbf622a931c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65df68bcd490477081b139da1ffc9c00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "814d24b4341e4940a40dd28ed5fdfc5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd44dfaf10fa4c4cb58d95b01897945b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2809a8d405d3475f9e35e31eeb06fa75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d3d5f5d7d148b9843b8760c9294dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a27c53159b348d589d81a8f10ba9525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c5f7c1e229a4339abb9f0b500322c37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characteristic vectors extracted successfully!\n",
      "Vector dimension: 384\n"
     ]
    }
   ],
   "source": [
    "# File: feature_extractor.py\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "class CharacteristicVectorExtractor:\n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2'):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        \n",
    "    def extract_characteristics(self, texts):\n",
    "        \"\"\"\n",
    "        Extract characteristic vectors for a list of texts\n",
    "        \"\"\"\n",
    "        characteristics = []\n",
    "        \n",
    "        for text in texts:\n",
    "            # Get embeddings\n",
    "            embedding = self.model.encode(text, show_progress_bar=False)\n",
    "            \n",
    "            # For simplicity, we use the embedding as characteristic vector\n",
    "            # In advanced version, we'll extract from each layer\n",
    "            char_vector = {\n",
    "                'embedding': embedding,\n",
    "                'mean': np.mean(embedding),\n",
    "                'std': np.std(embedding)\n",
    "            }\n",
    "            characteristics.append(char_vector)\n",
    "            \n",
    "        return characteristics\n",
    "    \n",
    "    def batch_extract(self, texts, batch_size=32):\n",
    "        \"\"\"Extract characteristics in batches\"\"\"\n",
    "        all_characteristics = []\n",
    "        \n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i+batch_size]\n",
    "            batch_chars = self.extract_characteristics(batch)\n",
    "            all_characteristics.extend(batch_chars)\n",
    "            \n",
    "        return all_characteristics\n",
    "\n",
    "# Test the extractor\n",
    "if __name__ == \"__main__\":\n",
    "    extractor = CharacteristicVectorExtractor()\n",
    "    test_texts = [\"This is a great movie\", \"Amazing storyline\"]\n",
    "    characteristics = extractor.extract_characteristics(test_texts)\n",
    "    print(\"Characteristic vectors extracted successfully!\")\n",
    "    print(f\"Vector dimension: {len(characteristics[0]['embedding'])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poisoning_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
