{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory: d:\\SKRIPSI\\Code\\poisoning_detection\\Src\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Working Directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\SKRIPSI\\Code\\poisoning_detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\SKRIPSI\\Code\\poisoning_detection\\poisoning_detection\\lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed centroids for 1798 genres\n",
      "Detection Accuracy: 0.816\n",
      "\n",
      "Sample predictions:\n",
      "Movie: Toy Story (1995)... | Prediction: CLEAN | Actual: CLEAN | Distance: 0.027\n",
      "Movie: Jumanji (1995)... | Prediction: CLEAN | Actual: CLEAN | Distance: 0.069\n",
      "Movie: Grumpier Old Men (1995)... | Prediction: CLEAN | Actual: CLEAN | Distance: 0.037\n",
      "Movie: Waiting to Exhale (1995)... | Prediction: CLEAN | Actual: CLEAN | Distance: 0.070\n",
      "Movie: Father of the Bride Part II (1... | Prediction: CLEAN | Actual: CLEAN | Distance: 0.145\n"
     ]
    }
   ],
   "source": [
    "# File: poison_detector.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "import random\n",
    "\n",
    "# Define missing classes\n",
    "class PoisonSimulator:\n",
    "    def __init__(self):\n",
    "        self.poison_keywords = ['free', 'download', 'watch now', 'click here', 'limited time', \n",
    "                               'exclusive', 'secret', 'hidden', 'special offer', 'buy now']\n",
    "    \n",
    "    def generate_poisoned_dataset(self, movies, poison_ratio=0.2):\n",
    "        \"\"\"Generate poisoned dataset by injecting malicious keywords\"\"\"\n",
    "        clean_df = movies.copy()\n",
    "        clean_df['is_poisoned'] = False\n",
    "        clean_df['poisoned_description'] = clean_df['title']  # Using title as placeholder\n",
    "        \n",
    "        # Create poisoned samples\n",
    "        n_poison = int(len(movies) * poison_ratio)\n",
    "        poison_indices = random.sample(range(len(movies)), n_poison)\n",
    "        \n",
    "        poisoned_df = movies.iloc[poison_indices].copy()\n",
    "        poisoned_df['is_poisoned'] = True\n",
    "        \n",
    "        # Add poison keywords to descriptions\n",
    "        poisoned_descriptions = []\n",
    "        for idx, row in poisoned_df.iterrows():\n",
    "            base_desc = row['title']\n",
    "            keyword = random.choice(self.poison_keywords)\n",
    "            poisoned_desc = f\"{base_desc} - {keyword}!\"\n",
    "            poisoned_descriptions.append(poisoned_desc)\n",
    "        \n",
    "        poisoned_df['poisoned_description'] = poisoned_descriptions\n",
    "        \n",
    "        return clean_df, poisoned_df\n",
    "\n",
    "class CharacteristicVectorExtractor:\n",
    "    def __init__(self, vector_size=50):\n",
    "        self.vector_size = vector_size\n",
    "    \n",
    "    def simple_embedding(self, text):\n",
    "        \"\"\"Create simple text embedding based on character frequencies\"\"\"\n",
    "        # Simple hash-based embedding for demonstration\n",
    "        text = text.lower()\n",
    "        embedding = np.zeros(self.vector_size)\n",
    "        \n",
    "        for i, char in enumerate(text[:self.vector_size]):\n",
    "            if i < len(text):\n",
    "                embedding[i] = ord(char) % 100 / 100.0  # Normalize\n",
    "        \n",
    "        # Fill remaining positions if text is shorter than vector_size\n",
    "        if len(text) < self.vector_size:\n",
    "            for i in range(len(text), self.vector_size):\n",
    "                embedding[i] = (i * 13) % 100 / 100.0  # Pseudo-random fill\n",
    "        \n",
    "        return embedding\n",
    "    \n",
    "    def extract(self, description):\n",
    "        \"\"\"Extract characteristic vector from description\"\"\"\n",
    "        embedding = self.simple_embedding(description)\n",
    "        return {\n",
    "            'embedding': embedding,\n",
    "            'length': len(description),\n",
    "            'has_special_chars': any(c in description for c in '!@#$%^&*()')\n",
    "        }\n",
    "    \n",
    "    def batch_extract(self, descriptions):\n",
    "        \"\"\"Extract characteristics for multiple descriptions\"\"\"\n",
    "        return [self.extract(desc) for desc in descriptions]\n",
    "\n",
    "class SimplePoisonDetector:\n",
    "    def __init__(self, threshold=0.8):\n",
    "        self.threshold = threshold\n",
    "        self.centroids = {}\n",
    "        self.is_fitted = False\n",
    "    \n",
    "    def compute_centroids(self, characteristics, genres):\n",
    "        \"\"\"Compute centroids for each genre\"\"\"\n",
    "        genre_vectors = {}\n",
    "        \n",
    "        for char_vec, genre in zip(characteristics, genres):\n",
    "            if genre not in genre_vectors:\n",
    "                genre_vectors[genre] = []\n",
    "            genre_vectors[genre].append(char_vec['embedding'])\n",
    "        \n",
    "        # Compute centroid for each genre\n",
    "        for genre, vectors in genre_vectors.items():\n",
    "            self.centroids[genre] = np.mean(vectors, axis=0)\n",
    "        \n",
    "        self.is_fitted = True\n",
    "        print(f\"Computed centroids for {len(self.centroids)} genres\")\n",
    "    \n",
    "    def detect_poison(self, characteristics, genres):\n",
    "        \"\"\"Detect poisoned items based on distance to centroid\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Detector not fitted. Call compute_centroids first.\")\n",
    "        \n",
    "        predictions = []\n",
    "        distances = []\n",
    "        \n",
    "        for char_vec, genre in zip(characteristics, genres):\n",
    "            if genre not in self.centroids:\n",
    "                # Unknown genre, mark as suspicious\n",
    "                predictions.append(True)\n",
    "                distances.append(1.0)\n",
    "                continue\n",
    "            \n",
    "            embedding = char_vec['embedding']\n",
    "            centroid = self.centroids[genre]\n",
    "            \n",
    "            # Compute cosine distance\n",
    "            similarity = cosine_similarity([embedding], [centroid])[0][0]\n",
    "            distance = 1 - similarity\n",
    "            \n",
    "            distances.append(distance)\n",
    "            predictions.append(distance > self.threshold)\n",
    "        \n",
    "        return predictions, distances\n",
    "\n",
    "# Test detector\n",
    "if __name__ == \"__main__\":\n",
    "    # Create sample data if file doesn't exist\n",
    "    try:\n",
    "        movies = pd.read_csv('data/ml-32m/movies.csv')\n",
    "    except:\n",
    "        print(\"CSV file not found, creating sample data...\")\n",
    "        # Create sample movie data\n",
    "        movies_data = {\n",
    "            'movieId': range(1, 101),\n",
    "            'title': [f'Movie {i}' for i in range(1, 101)],\n",
    "            'genres': ['Action'] * 25 + ['Comedy'] * 25 + ['Drama'] * 25 + ['Horror'] * 25\n",
    "        }\n",
    "        movies = pd.DataFrame(movies_data)\n",
    "    \n",
    "    # Generate poisoned data\n",
    "    simulator = PoisonSimulator()\n",
    "    clean_df, poisoned_df = simulator.generate_poisoned_dataset(movies, poison_ratio=0.2)\n",
    "    \n",
    "    # Extract characteristics\n",
    "    extractor = CharacteristicVectorExtractor()\n",
    "    \n",
    "    # Combine clean and poisoned for testing\n",
    "    test_df = pd.concat([clean_df, poisoned_df[poisoned_df['is_poisoned'] == True]])\n",
    "    descriptions = test_df['poisoned_description'].tolist()\n",
    "    genres = test_df['genres'].tolist()\n",
    "    true_labels = test_df['is_poisoned'].tolist()\n",
    "    \n",
    "    characteristics = extractor.batch_extract(descriptions)\n",
    "    \n",
    "    # Train detector on clean data only\n",
    "    clean_chars = [c for c, label in zip(characteristics, true_labels) if not label]\n",
    "    clean_genres = [g for g, label in zip(genres, true_labels) if not label]\n",
    "    \n",
    "    detector = SimplePoisonDetector(threshold=0.3)\n",
    "    detector.compute_centroids(clean_chars, clean_genres)\n",
    "    \n",
    "    # Test detection\n",
    "    predictions, distances = detector.detect_poison(characteristics, genres)\n",
    "    \n",
    "    # Evaluate\n",
    "    accuracy = np.mean([p == tl for p, tl in zip(predictions, true_labels)])\n",
    "    print(f\"Detection Accuracy: {accuracy:.3f}\")\n",
    "    \n",
    "    # Print some examples\n",
    "    print(\"\\nSample predictions:\")\n",
    "    for i in range(min(5, len(predictions))):\n",
    "        status = \"POISONED\" if predictions[i] else \"CLEAN\"\n",
    "        actual = \"POISONED\" if true_labels[i] else \"CLEAN\"\n",
    "        print(f\"Movie: {descriptions[i][:30]}... | Prediction: {status} | Actual: {actual} | Distance: {distances[i]:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poisoning_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
